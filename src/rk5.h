/*
Copyright (C) 2020 Bruno Golosio
This program is free software: you can redistribute it and/or modify
it under the terms of the GNU General Public License as published by
the Free Software Foundation, either version 3 of the License, or
(at your option) any later version.
This program is distributed in the hope that it will be useful,
but WITHOUT ANY WARRANTY; without even the implied warranty of
MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
GNU General Public License for more details.
You should have received a copy of the GNU General Public License
along with this program.  If not, see <http://www.gnu.org/licenses/>.
*/

#ifndef RK5H
#define RK5H

#include "cuda_error.h"
#include "rk5_const.h"
#include "rk5_interface.h"

#define MIN(a,b) (((a)<(b))?(a):(b))
#define MAX(a,b) (((a)>(b))?(a):(b))

extern __constant__ int NeuronGPUTimeIdx; // temporary for check, remove

__global__ void SetFloatArray(float *arr, int n_elem, int step, float val);

template<class DataStruct>
__global__
void ArrayInit(int array_size, int n_var, int n_param, float *x_arr,
	       float *h_arr, float *y_arr, float *par_arr, float x_min,
	       float h, DataStruct data_struct)
{
  int array_idx = threadIdx.x + blockIdx.x * blockDim.x;
  if (array_idx<array_size) {
    NodeInit(n_var, n_param, x_min, &y_arr[array_idx*n_var],
	     &par_arr[array_idx*n_param], data_struct);
    x_arr[array_idx] = x_min;
    h_arr[array_idx] = h;
  }
}

template<class DataStruct>
__global__
void ArrayCalibrate(int array_size, int n_var, int n_param, float *x_arr,
		    float *h_arr, float *y_arr, float *par_arr, float x_min,
		    float h, DataStruct data_struct)
{
  int array_idx = threadIdx.x + blockIdx.x * blockDim.x;
  if (array_idx<array_size) {
    NodeCalibrate(n_var, n_param, x_min, &y_arr[array_idx*n_var],
		  &par_arr[array_idx*n_param], data_struct);
    x_arr[array_idx] = x_min;
    h_arr[array_idx] = h;
  }
}

template<int NVAR, int NPARAM, class DataStruct>
__device__
void RK5Step(float &x, float *y, float &h, float h_min, float h_max,
	     float *param, DataStruct data_struct)
{
  float y_new[NVAR];
  float k1[NVAR];
  float k2[NVAR];
  float k3[NVAR];
  float k4[NVAR];
  float k5[NVAR];
  float k6[NVAR];
  float y_scal[NVAR];

  Derivatives<NVAR, NPARAM>(x, y, k1, param, data_struct);
  for (int i=0; i<NVAR; i++) {
    y_scal[i] = fabs(y[i]) + fabs(k1[i]*h) + scal_min;
  }
  
  float err;
  for(;;) {
    if (h > h_max) h = h_max;
    
    if (NeuronGPUTimeIdx==000 || NeuronGPUTimeIdx==611) {
      printf("x: %f h:%f\n", x, h);
    }
    
    for (int i=0; i<NVAR; i++) {
      y_new[i] = y[i] + h*a21*k1[i];
    }
    //if (NeuronGPUTimeIdx==000 || NeuronGPUTimeIdx==611) {
      printf("x: %f h:%f ", x, h);
      for (int i=0; i<NVAR; i++) {
	printf("\t%f", y_new[i]);
      }
      printf("\n");
      //}
    Derivatives<NVAR, NPARAM>(x+c2*h, y_new, k2, param,
			      data_struct);
  
    for (int i=0; i<NVAR; i++) {
      y_new[i] = y[i] + h*(a31*k1[i] + a32*k2[i]);
    }
    Derivatives<NVAR, NPARAM>(x+c3*h, y_new, k3, param,
			      data_struct);

    for (int i=0; i<NVAR; i++) {
      y_new[i] = y[i] + h*(a41*k1[i] + a42*k2[i] + a43*k3[i]);
    }
    Derivatives<NVAR, NPARAM>(x+c4*h, y_new, k4, param,
			      data_struct);
  
    for (int i=0; i<NVAR; i++) {
      y_new[i] = y[i] + h*(a51*k1[i] + a52*k2[i] + a53*k3[i] + a54*k4[i]);
    }
    Derivatives<NVAR, NPARAM>(x+c5*h, y_new, k5, param,
			      data_struct);
  
    for (int i=0; i<NVAR; i++) {
      y_new[i] = y[i] + h*(a61*k1[i] + a62*k2[i] + a63*k3[i] + a64*k4[i]
			  + a65*k5[i]);
    }
    Derivatives<NVAR, NPARAM>(x+c6*h, y_new, k6, param, data_struct);
    
    for (int i=0; i<NVAR; i++) {
      y_new[i] = y[i] + h*(a71*k1[i] + a73*k3[i] + a74*k4[i] + a76*k6[i]);
    }
  
    err = 0.0;
    for (int i=0; i<NVAR; i++) {
      if (NeuronGPUTimeIdx==000 || NeuronGPUTimeIdx==611) {
	printf("i:%d k: %f %f %f %f %f %f\n",
	       i, k1[i], k3[i], k4[i], k5[i], k6[i], k2[i]);
	printf("h:%f ek: %lf %lf %lf %lf %lf\n",
	       h, e1*k1[i], e3*k3[i], e4*k4[i], e5*k5[i], e6*k6[i]);
	printf("y:%f y_new:%f\n", y[i], y_new[i]);
      }
      printf("sum: %e\n", e1*k1[i] + e3*k3[i] + e4*k4[i] + e5*k5[i]
	     + e6*k6[i]);
      float val = h*(e1*k1[i] + e3*k3[i] + e4*k4[i] + e5*k5[i] + e6*k6[i]);
      val /= y_scal[i]; ///// check for overflow!!!!!!!!!!!
      err = MAX(err,fabs(val));
      if (NeuronGPUTimeIdx==000 || NeuronGPUTimeIdx==611) {
	printf("val:%f err:%f\n", val, err);
      }
    }
    err /= eps;
    if (err <= 1.0) break;
    //break;

    float h_new = h*coeff*pow(err,exp_dec);
    h = MAX(h_new, 0.1*h);
    
    if (NeuronGPUTimeIdx==000 || NeuronGPUTimeIdx==611) {
      printf("err:%f h_new:%f h:%f\n",
	     err, h_new, h);
    }
    //if (h <= h_min) {
    //  h = h_min;
    //}
    //x_new = x + h;
  }

  x += h;  

  if (err > err_min) {
    h = h*coeff*pow(err,exp_inc);
  }
  else {
    h = 5.0*h;
  }
  
  for (int i=0; i<NVAR; i++) {
    y[i] = y_new[i];
  }

}

template<int NVAR, int NPARAM, class DataStruct>
__device__
void RK5Update(float &x, float *y, float x1, float &h, float h_min,
	       float *param, DataStruct data_struct)
{
  //if (NeuronGPUTimeIdx==000 || NeuronGPUTimeIdx==611) {
  printf("%d\n", NeuronGPUTimeIdx);
    printf("rk5u x: %f h:%f\n", x, h);
    //}

  bool end_time_step=false;
  while(!end_time_step) {
    float hmax=x1-x;
    RK5Step<NVAR, NPARAM, DataStruct>(x, y, h, h_min, hmax, param,
				       data_struct);
    end_time_step = (x >= x1-h_min);
    ExternalUpdate<NVAR, NPARAM>(x, y, param, end_time_step, data_struct);
  }
}

template<int NVAR, int NPARAM, class DataStruct>
__global__
void ArrayUpdate(int array_size, float *x_arr, float *h_arr, float *y_arr,
		 float *par_arr, float x1, float h_min, DataStruct data_struct)
{
  int ArrayIdx = threadIdx.x + blockIdx.x * blockDim.x;
  if (ArrayIdx<array_size) {
    float x = x_arr[ArrayIdx];
    float h = h_arr[ArrayIdx];
    float y[NVAR];
    float param[NPARAM];

    for(int i=0; i<NVAR; i++) {
      y[i] = y_arr[ArrayIdx*NVAR + i];
    }
    for(int j=0; j<NPARAM; j++) {
      param[j] = par_arr[ArrayIdx*NPARAM + j];
    }

    RK5Update<NVAR, NPARAM, DataStruct>(x, y, x1, h, h_min, param,
					 data_struct);

    x_arr[ArrayIdx] = x;
    h_arr[ArrayIdx] = h;
    for(int i=0; i<NVAR; i++) {
      y_arr[ArrayIdx*NVAR + i] = y[i];
    }
    for(int j=0; j<NPARAM; j++) {
      par_arr[ArrayIdx*NPARAM + j] = param[j]; 
    }
  }
}

template<class DataStruct>
class RungeKutta5
{
  int array_size_;
  int n_var_;
  int n_param_;
    
  float *d_XArr;
  float *d_HArr;
  float *d_YArr;
  float *d_ParamArr;

  public:

  ~RungeKutta5();
 
  float *GetXArr() {return d_XArr;}
  float *GetHArr() {return d_HArr;}
  float *GetYArr() {return d_YArr;}
  float *GetParamArr() {return d_ParamArr;}
  int Init(int array_size, int n_var, int n_param, float x_min, float h,
	   DataStruct data_struct);
  int Calibrate(float x_min, float h, DataStruct data_struct);

  int Free();

  int GetX(int i_array, int n_elem, float *x);
  int GetY(int i_var, int i_array, int n_elem, float *y);
  int SetParam(int i_param, int i_array, int n_param, int n_elem, float val);
  int SetVectParam(int i_param, int i_array, int n_param, int n_elem,
		    float *param, int vect_size);
  template<int NVAR, int NPARAM> int Update(float x1, float h_min,
					     DataStruct data_struct);

};


template<class DataStruct>
template<int NVAR, int NPARAM>
  int RungeKutta5<DataStruct>::Update(float x1, float h_min,
				      DataStruct data_struct)
{
  ArrayUpdate<NVAR, NPARAM, DataStruct><<<(array_size_+1023)/1024, 1024>>>
    (array_size_, d_XArr, d_HArr, d_YArr, d_ParamArr, x1, h_min, data_struct);
  gpuErrchk( cudaPeekAtLastError() );
  gpuErrchk( cudaDeviceSynchronize() );

  return 0;
}

template<class DataStruct>
RungeKutta5<DataStruct>::~RungeKutta5()
{
  Free();
}

template<class DataStruct>
int RungeKutta5<DataStruct>::Free()
{
  cudaFree(d_XArr);
  cudaFree(d_HArr);
  cudaFree(d_YArr);
  cudaFree(d_ParamArr);

  return 0;
}

template<class DataStruct>
int RungeKutta5<DataStruct>::Init(int array_size, int n_var, int n_param,
				  float x_min, float h,
				  DataStruct data_struct)
{
  array_size_ = array_size;
  n_var_ = n_var;
  n_param_ = n_param; 

  gpuErrchk(cudaMalloc(&d_XArr, array_size_*sizeof(float)));
  gpuErrchk(cudaMalloc(&d_HArr, array_size_*sizeof(float)));
  gpuErrchk(cudaMalloc(&d_YArr, array_size_*n_var_*sizeof(float)));
  gpuErrchk(cudaMalloc(&d_ParamArr, array_size_*n_param_*sizeof(float)));

  ArrayInit<DataStruct><<<(array_size+1023)/1024, 1024>>>
    (array_size_, n_var, n_param, d_XArr, d_HArr, d_YArr, d_ParamArr,
     x_min, h, data_struct);
  gpuErrchk( cudaPeekAtLastError() );
  gpuErrchk( cudaDeviceSynchronize() );
  
  return 0;
}

template<class DataStruct>
int RungeKutta5<DataStruct>::Calibrate(float x_min, float h,
				       DataStruct data_struct)
{
  ArrayCalibrate<DataStruct><<<(array_size_+1023)/1024, 1024>>>
    (array_size_, n_var_, n_param_, d_XArr, d_HArr, d_YArr, d_ParamArr,
     x_min, h, data_struct);
  gpuErrchk( cudaPeekAtLastError() );
  gpuErrchk( cudaDeviceSynchronize() );

  return 0;
}

template<class DataStruct>
int RungeKutta5<DataStruct>::GetX(int i_array, int n_elem, float *x)
{
  cudaMemcpy(x, &d_XArr[i_array], n_elem*sizeof(float),
	     cudaMemcpyDeviceToHost);

  return 0;
}

template<class DataStruct>
int RungeKutta5<DataStruct>::GetY(int i_var, int i_array, int n_elem, float *y)
{
  cudaMemcpy(y, &d_YArr[i_array*n_var_ + i_var], n_elem*sizeof(float),
	     cudaMemcpyDeviceToHost);

  return 0;
}

template<class DataStruct>
int RungeKutta5<DataStruct>::SetParam(int i_param, int i_array, int n_param,
			   int n_elem, float val)
{
  SetFloatArray<<<(n_elem+1023)/1024, 1024>>>
    (&d_ParamArr[i_array*n_param_ + i_param], n_elem, n_param, val);
  gpuErrchk( cudaPeekAtLastError() );
  gpuErrchk( cudaDeviceSynchronize() );
  
  return 0;
}

#endif
